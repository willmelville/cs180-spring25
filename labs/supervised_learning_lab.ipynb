{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this lab is to practice training and evaluating different types of regression and classification models.\n",
        "\n",
        "In part 1, you will practice doing regression on the auto mpg dataset from the UC Irvine Machine Learning Repository https://archive.ics.uci.edu/dataset/9/auto+mpg. The goal is to learn a regression model to predict the miles per gallon of a car given its displacement, cylinders, horsepower, weight, and acceleration.\n",
        "\n",
        "In part 2, you will practice doing binary classification on a breast cancer diagnostic dataset. The measurements in the dataset are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe the charactersitics of the cell nuclei present in the image. Each image is diagnosed as either benign or malignant, and your goal is to learn a binary classifier to predict benign or malignant.\n",
        "\n",
        "**Important Note**: Normally I would strongly discourage doing machine learning without first doing exploratory analysis to thoughtfully select the appropriate features to include in the model, as well as to do any necessary feature engineering. However, the goal of this lab is to practice with the different regression and classification models that we have learned about in class and to practice with the different evaluation metrics, so you will not be doing any EDA or feature selection or feature engineering in this lab. You will just use the data and features that are provided. But, be warned that on your final and in your future careers as expert data scientists, my expectation is that you are thoughtful about what features you include in your machine learning models. Don't let me down!"
      ],
      "metadata": {
        "id": "acLN9ycIvQEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#you need the ucimlrepo package to get the miles per gallon dataset, which you can install in google colab using the following command\n",
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCMtXCryzH9n",
        "outputId": "265187c2-c19f-4d2d-d39f-073894316db5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZA7dgltjuVfe"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn import datasets\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.metrics import r2_score, root_mean_squared_error, mean_squared_error, mean_absolute_error, classification_report, confusion_matrix, accuracy_score, log_loss, roc_curve, roc_auc_score, RocCurveDisplay, precision_recall_curve, PrecisionRecallDisplay\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.calibration import CalibrationDisplay, calibration_curve"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 1: Regression on the MPG dataset**"
      ],
      "metadata": {
        "id": "rQwellny5YC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "auto_mpg = fetch_ucirepo(id=9)\n",
        "X = auto_mpg.data.features\n",
        "Y = auto_mpg.data.targets\n",
        "\n",
        "df = X[['displacement', 'cylinders', 'horsepower', 'weight', 'acceleration']]\n",
        "df['mpg'] = Y.values\n",
        "\n",
        "df = df.dropna()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQyuqBDFwnHC",
        "outputId": "34828f7b-5547-4cf6-e897-a633260249c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-7f82b5e9fe21>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['mpg'] = Y.values\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mpg data with all the columns you need is now loaded into the pandas dataframe `df`. Remember that it is very important in machine learning to test your models on a holdout test dataset, so your first task is to perform an 80/20 train test split on the dataset."
      ],
      "metadata": {
        "id": "mErgxeZz7oTH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your train/test split code here\n"
      ],
      "metadata": {
        "id": "a4wYQpHqwohU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 1a: Linear Regression**\n",
        "\n",
        "In this part of the lab, use your train dataset to learn a linear regression model to predict the mpg column using the displacement, cylinders, horsepower, weight, and acceleration columns. Then evaluate your trained linear regression model by doing the following:\n",
        "\n",
        "1. Create a scatter plot of your predicted miles per gallon on the x axis and the actual miles per gallon on the y axis. Do this for both the train set and the test set, so create two scatter plots. Add a line to your plots with slope = 1 and intercept = 0. That line represents your linear model predictions, so it will help you see how close your predictions are to the actual values. Label your x axis \"Predicted MPG\", and label your y axis \"Actual MPG\". Add a title to your plot to signify if it is for the test set or the train set.\n",
        "\n",
        "2. Calculate the mean absolute error (MAE) of your predictions on both the train set and test set\n",
        "\n",
        "3. Calculate the root mean squared error (RMSE) of your predictions on both the train set and test set\n",
        "\n",
        "4. Calculate the $r^2$ score of your predictions on both the train set and test set\n",
        "\n",
        "After calculating the $r^2$ scores, interpret them. For example, if you find that the $r^2$ in your test set is 0.55, what does that mean? Type it out."
      ],
      "metadata": {
        "id": "6TIXgfPF8l5o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train your linear regression model here\n"
      ],
      "metadata": {
        "id": "NjLpTpiJ4V77"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create your train and test set scatter plots\n"
      ],
      "metadata": {
        "id": "ekpjp6Rc8M4p"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the train set MAE and test set MAE. Print both\n"
      ],
      "metadata": {
        "id": "3YUH4zoH_AG9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the train set RMSE and test set RMSE. Print both\n"
      ],
      "metadata": {
        "id": "jOBYVlPS_fwc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the train set r squared and test set r squared. Print both\n"
      ],
      "metadata": {
        "id": "tf0YbPP1_spv"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpret your $r^2$ scores here:**\n",
        "\n"
      ],
      "metadata": {
        "id": "gDoFbMRDANx0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 1b: Random Forest**\n",
        "\n",
        "Repeat everything you did in part 1a, only this time fit a random forest regression model."
      ],
      "metadata": {
        "id": "nlcHhiGLAhvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train your random forest regression model here\n"
      ],
      "metadata": {
        "id": "YMYBUuXYAgPz"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create your train and test set scatter plots\n"
      ],
      "metadata": {
        "id": "Baut1ypYA4ub"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the train set MAE and test set MAE. Print both\n"
      ],
      "metadata": {
        "id": "Fg7F_zkeA9TL"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the train set RMSE and test set RMSE. Print both\n"
      ],
      "metadata": {
        "id": "5qreqme9BDIM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the train set r squared and test set r squared. Print both\n"
      ],
      "metadata": {
        "id": "huUgAqX7BD1U"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpret your $r^2$ scores here:**\n"
      ],
      "metadata": {
        "id": "KsvYe-HABI-p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 1c: Boosting**\n",
        "\n",
        "Redo everything you did in part 1a, but this time use some choice of boosting model (Gradient boost, XGBoost, LightGBM, etc)."
      ],
      "metadata": {
        "id": "-JhJzFCbByba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#train your boosting regression model here\n"
      ],
      "metadata": {
        "id": "xULd4q_JBF2Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create your train and test set scatter plots\n"
      ],
      "metadata": {
        "id": "x2sMxv6qCCxy"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the train set MAE and test set MAE. Print both\n"
      ],
      "metadata": {
        "id": "WztK0-DCCGbE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the train set RMSE and test set RMSE. Print both\n"
      ],
      "metadata": {
        "id": "i4YaZ89CCI5g"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the train set r squared and test set r squared. Print both\n"
      ],
      "metadata": {
        "id": "UGmW9OAdCP1k"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Interpret your $r^2$ scores here:**\n"
      ],
      "metadata": {
        "id": "RxShh-vcCXtH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 1d**\n",
        "\n",
        "Now that you have fit and evaluated three different models, answer these questions.\n",
        "\n",
        "1. Which regression model would you choose to predict automobile miles per gallon. Justify your answer.\n",
        "\n",
        "2. Is there evidence of overfitting in any of these models? If so, which ones and what is the evidence?"
      ],
      "metadata": {
        "id": "0Iskmj5iC-4X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer question 1 here:**"
      ],
      "metadata": {
        "id": "36Sxtye_DWAh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer question 2 here**\n"
      ],
      "metadata": {
        "id": "GAT8gEpeDV9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Part 2: Classification on the breast cancer dataset**\n",
        "\n",
        "Pay a little bit more attention to the instructions in each subpart of part 2. Classifiers have lots of different evaluation metrics, so I don't make you calculate all of them in each subpart, so you can't just blindly copy and paste your code from prior subparts this time."
      ],
      "metadata": {
        "id": "q20lDrYEDxu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the dataset\n",
        "bc = datasets.load_breast_cancer(as_frame = True)\n",
        "X = bc['data']\n",
        "Y = bc['target']\n",
        "df = X[['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension']]\n",
        "df.columns = ['radius', 'texture', 'perimeter', 'area', 'smoothness', 'compactness', 'concavity', 'conc_points', 'symmetry', 'fractal_dim']\n",
        "df['is_malignant'] = Y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkaspfZQD7GP",
        "outputId": "95b83823-8299-4f94-bb94-2adaa5ecdde0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-cd198f95d806>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df['is_malignant'] = Y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The breast cancer data with all the columns you need is now loaded into the pandas dataframe `df`. Remember that it is very important in machine learning to test your models on a holdout test dataset, so your first task is to perform an 80/20 train test split on the dataset."
      ],
      "metadata": {
        "id": "FuQziEicVjFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#perform the 80/20 train test split here\n"
      ],
      "metadata": {
        "id": "eVwR4MxWVDvk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2a: Logistic Regression**\n",
        "\n",
        "In this part of the lab, use your train dataset to learn a logistic regression model to predict the is_malignant using the other ten columns as predictor variables. Then evaluate your trained logistic regression model by doing the following:\n",
        "\n",
        "1. Calculate the precision, recall, and f1 score on both the train and test set (**Hint**: print the results of sklearn.metrics.classification_report)\n",
        "\n",
        "2. Plot a calibration curve for both the train and test set. Use sklearn's functions calibration_curve and CalibrationDisplay to do this, and use strategy = 'quantile' in the calibration_curve function.\n",
        "\n",
        "3. Calculate the log loss (cross entropy loss) on both the train and test set\n",
        "\n",
        "4. Calculate the accuracy on both the train and test set\n",
        "\n",
        "5. Create a confusion matrix on both the train and test set. Use the confusion matrix to calculate specificity (true negatives / (true negatives + false positives)) on both the train and test set."
      ],
      "metadata": {
        "id": "3grb6wI-dHqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train your logistic regression model here\n"
      ],
      "metadata": {
        "id": "7W5X3uVOe2NH"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the precision, recall, and f1 on both the train and test set\n"
      ],
      "metadata": {
        "id": "v_7cgQCbe2J_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a calibration curve for both the train and test set\n"
      ],
      "metadata": {
        "id": "e6e4IE7ne2Fc"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the log loss on the train and test set\n"
      ],
      "metadata": {
        "id": "mQAoPsAEe2DA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the accuracy on the train and test set\n"
      ],
      "metadata": {
        "id": "7-7ue3CxgoQK"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a confusion matrix for both the train and test set.\n"
      ],
      "metadata": {
        "id": "84lw8AFyg2C7"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the specificity on the train and test set? Answer here using your confusion matrices:**\n"
      ],
      "metadata": {
        "id": "MA8Jn4gghH5q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2b: Random Forest**\n",
        "\n",
        "Train a random forest classifier on the breast cancer data to predict is_malignant. Then, repeat steps 1-4 from part 2a. Finally, Plot a ROC curve on the train and test set and report the areas under those curves. To make the plots, you may want to use the roc_curve and RocCurveDisplay functions from sklearn.metrics."
      ],
      "metadata": {
        "id": "zP7LxXAHhuo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train your random forest model here\n"
      ],
      "metadata": {
        "id": "Mzzpwgp-hHNI"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the precision, recall, and f1 on both the train and test set\n"
      ],
      "metadata": {
        "id": "fvjgk4PHiLxG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a calibration curve for both the train and test set\n"
      ],
      "metadata": {
        "id": "iJHEvctwiLui"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the log loss on the train and test set\n"
      ],
      "metadata": {
        "id": "zWt8zOo2iLrs"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the accuracy on the train and test set\n"
      ],
      "metadata": {
        "id": "bwz1mi9PiLpa"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot ROC curves for both the train and test set\n"
      ],
      "metadata": {
        "id": "uJ6ThD5RiLma"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#report the area under the train and test roc curves\n"
      ],
      "metadata": {
        "id": "_BIZvcQBk3P7"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2c: Boosting**\n",
        "\n",
        "Train your choice of boosting model (gradient boosting, xgboost, ligthgbm, etc.) on the breast cancer dataset to predict is_malignant. Repeat steps 1-4 from part 2a. Finally, plot a precision-recall curve for both the train and test set. You may want to use the precision_recall_curve and PrecisionRecallDisplay functions from sklearn.metrics to do this."
      ],
      "metadata": {
        "id": "U3DN-cvWlQ9S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train your boosting model here\n"
      ],
      "metadata": {
        "id": "8TVdCEmUVFbE"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the precision, recall, and f1 on both the train and test set\n"
      ],
      "metadata": {
        "id": "cb_ER7T_ltGd"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot a calibration curve for both the train and test set\n"
      ],
      "metadata": {
        "id": "IjADAtL-lvco"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the log loss on the train and test set\n"
      ],
      "metadata": {
        "id": "3k0huYp9lysw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calculate the accuracy on the train and test set\n"
      ],
      "metadata": {
        "id": "K427GiDEl2JD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot precision-recall curves for the train and test sets\n"
      ],
      "metadata": {
        "id": "edg8QqsKl53L"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2d**\n",
        "\n",
        "Now that you have fit and evaluated three different models, answer these questions.\n",
        "\n",
        "1. Which binary classification model would you choose to predict breast cancer. Justify your answer.\n",
        "\n",
        "2. Is there evidence of overfitting in any of these models? If so, which ones and what is the evidence?"
      ],
      "metadata": {
        "id": "_Tbj1RHZo_dZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer question 1 here:**"
      ],
      "metadata": {
        "id": "45zZ5VyjrzdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Answer question 2 here:**"
      ],
      "metadata": {
        "id": "mB8D8HOgr2Mz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Great Work!** I just wanted to leave you all this final note on classifiers. In job interviews you may get asked about confusion matrices and roc curves and precision and recall and all that stuff, so it's worth knowing about. However, in practice (once you pass the job interview and get the job) you rarely need to use all of them. I (Will Melville) usually just look at log loss and calibration curves and that is it. Of course, in baseball we primarily care about the predicted probabilities rather than the predicted classes. For example, batting averages and on base percentages and lots of other baseball statistics are just probabilities. Baseball people like to think in terms of probabilities. Thus, I gravitate towards the metrics (log loss and calibration curves) that test if my model is outputting good probabilities. There may be other industries where they care more about the predicted classes rather than the predicted probabilities, in which case you may gravitate more towards things like precision, recall, and F1 and away from log loss and calibration curves. Have data science feel and choose the right evaluation metrics for the job!"
      ],
      "metadata": {
        "id": "xwjlluH6m4DQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ClD9EjLHmZpv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Baseball Pitches**\n",
        "\n",
        "Scouts and baseball players can look at a pitch and tell if it is a fastball, breaking ball, or offspeed pitch. Baseball data scientists, on the other hand, often can't tell just by looking at the pitch. However, they can distinguish pitch types by looking at measurements of their velocity, spin rate, and spin induced movement. In this lab, you will cluster pitch data on these measurements and see if you can identify the clusters of different pitch types!\n",
        "\n",
        "<br>\n",
        "\n",
        "**The Dataset**\n",
        "\n",
        "For this lab, we will be using data from one of the greatest pitchers of all time, Jacob DeGrom. The dataset contains measurements on the release speed (mph), spin rate (rpm), spin induced horizontal movement (inches), and spin induced vertical movement (inches) on 1632 pitches thrown by DeGrom as a member of the Texas Rangers. The dataset also contains the pitch type (fastball, curveball, slider, or changeup) and pitch type category (fastball, offspeed, or breaking ball), but we are doing unsupervised learning so we won't worry about those labels until we have our clusters defined.\n",
        "\n",
        "<br>\n",
        "\n",
        "It is worth mentioning that horizontal break is measured from the catcher's perspective, so a negative horizontal break means the ball moved towards third base and a positive horizontal break means it moved towards first base."
      ],
      "metadata": {
        "id": "OzRJ6sl8LSil"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfyGmlBwK6bV"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#read in the dataset\n",
        "data = pd.read_csv('https://raw.githubusercontent.com/willmelville/cs180-spring25/refs/heads/main/data/degrom_pitches.csv')\n",
        "\n",
        "#lucky for you, I took care of step 1 of the EDA checklist for you. I decided to just remove these outlier measurements\n",
        "data = data.loc[(data.pitch_type != 'Fastball') | (data.spin_rate >= 2300)]\n",
        "data = data.loc[(data.pitch_type != 'Fastball') | (data.spin_rate < 2700)]\n",
        "data = data.loc[(data.pitch_type != 'Slider') | (data.spin_rate < 2900)]\n",
        "data = data.loc[(data.pitch_type != 'Slider') | (data.spin_rate >= 2450)]\n",
        "data = data.loc[(data.pitch_type != 'Slider') | (data.release_speed < 95)]\n",
        "data = data.loc[(data.pitch_type != 'Curveball') | (data.release_speed < 86)]\n",
        "data = data.loc[(data.pitch_type != 'Curveball') | (data.release_speed > 75)]\n",
        "data.head()"
      ],
      "metadata": {
        "id": "mW1rNk9ONRQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 1**: KMeans\n",
        "\n",
        "In part 1, we will use KMeans to cluster DeGrom's pitches. But before we do that, we should do some EDA. Fortunately, I already dealt with missing data and outliers for you, so you can skip that part of the checklist. Additionally, we know from class that when we do KMeans clustering we want to standardize all the variables so they are measured on the same scale, so we are going to skip steps 2 and 3 of the checklist for now and start with step 4 by standardizing the variables.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Problem 1:** standardize the release speed, spin rate, horizontal break, and induced vertical break columns by z-scoring them. You may do it manually, but you may also use sklearn's z scoring function: StandardScaler. Note another good option for this would be the MinMaxScaler, which scales values between 0 and 1. Both will transform the variables so that they are all measured on the same scale, so both options work, but for this lab use the StandardScaler."
      ],
      "metadata": {
        "id": "tcZ35ks-P7KD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#problem 1\n"
      ],
      "metadata": {
        "id": "lFs6NpvIVFbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2a**: Now we circle back to steps 2 and 3 in the EDA checklist. When doing clustering, it's a good idea to plot the variables you want to use to define the clusters in a scatter plot or a joint distribution plot (sns.jointplot with two variables at a time). This may give you an idea of how many clusters you will want to use in the kmeans algorithm. Plot a seaborn pairplot of the numerical variables in the dataset. Based on what you see, answer how many clusters you think you may want to use in the KMeans algorithm."
      ],
      "metadata": {
        "id": "KGU_L59iVTIT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#problem 2a code\n"
      ],
      "metadata": {
        "id": "pg_iP5UVXmUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2a written response**: How many clusters do you think you should use in the kmeans algorithm based on these plots?"
      ],
      "metadata": {
        "id": "vScE0MuYFDJG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write your answer here**:"
      ],
      "metadata": {
        "id": "-7As9gyVF1ds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 2b**: Redo problem 2a but this time color the points by pitch type. Typically in unsupervised learning/clustering problems we don't have labels for our data so we wouldn't necessarily be able to do this, but we know what types of pitches DeGrom throws so in this case we can see how the pitch types give us some natural clustering."
      ],
      "metadata": {
        "id": "kPgouU-kYziP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#problem 2b\n"
      ],
      "metadata": {
        "id": "FlZAWbe_NgXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 3a**: That's enough EDA. Now we can begin KMeans. First we need to decide how many clusters we want to use. Using your choice of either the elbow method/within cluster sum of squares or the silhouette method or both if you're a real overachiever, figure out the optimal number of clusters. Test K values ranging from 2 to 10. Be sure to plot the elbow curve if you choose within cluster sum of squares or the silhouette curve if you choose the silhouette method to justify your choice of K."
      ],
      "metadata": {
        "id": "tp-466HvbBA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# problem 3a\n"
      ],
      "metadata": {
        "id": "f2wnbXEMQatn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How many clusters would you recommend? Answer here:**"
      ],
      "metadata": {
        "id": "Nu-TusdzdL1b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 3b**: Have some feel! Does the number of clusters you got in problem 3a match the number of pitch types that DeGrom throws? Knowing how many pitch types DeGrom throws, do you think you could have skipped the elbow method/silhouette test?"
      ],
      "metadata": {
        "id": "siqWQ4FvdJcH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3b answer here:**"
      ],
      "metadata": {
        "id": "YTD2Jco1LFjo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 4a** Regardless of what you got in problems 3a and 3b, choose K = 4 and run KMeans on the dataset. Assign a cluster label to each row in the dataset. Then redo the plot in exercise 2b, but this time use your cluster label instead of the pitch type. Do you find similar clusters using KMeans that you get when you just cluster by pitch type? Feel free to replot the plot from 2b in a cell down here so that it's easier to compare with the new plot that uses your cluster labels."
      ],
      "metadata": {
        "id": "mByz0H-3LEsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# problem 4a\n"
      ],
      "metadata": {
        "id": "AQ19a8taLz1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 4b**: Now you are a baseball pitching expert! Answer how can you use horizontal break, vertical break, release speed, and/or spin rate to distinguish between DeGrom's changeup and fastball? Likewise, how can you use horizontal break, vertical break, release speed, and/or spin rate to distinguish between DeGrom's slider and curveball?"
      ],
      "metadata": {
        "id": "ydrE5HZLMoyG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 4b answer here:**"
      ],
      "metadata": {
        "id": "UVXpGtY4M_Mv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2**: Gaussian Mixture Models\n",
        "\n",
        "In part 2, we are again going to cluster DeGrom's pitches, but this time we are going to use a gaussian mixture model instead of KMeans. Continue using the transformed dataset that you used in part 1 that has the columns z scored.\n",
        "\n",
        "<br>\n",
        "\n",
        "**Problem 5**: We're going to start again with some exploratory data analysis. GMM's should work best when our data is multimodal and when each mode or peak looks like it could be the peak of its own normal distribution. Choose an appropriate distribution plot (boxplot, KDE, histogram, or violinplot) to plot each of release speed, horizontal break, induced vertical break, and spin rate. Does the data look multimodal to you? Does each peak look like it could be fit with a normal distribution?\n",
        "\n",
        "**Note** what we really want to know is if the 4-dimensional vector of release speed, horizontal break, induced vertical break, and spin rate looks multimodal with peaks that could be fit with a 4-d normal distribution, but we can't easily visualize that so that's why for this problem you just need to look at each of those four measurements in 1 dimension."
      ],
      "metadata": {
        "id": "hQcyxDd_NFdc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#problem 5\n"
      ],
      "metadata": {
        "id": "-E2wlL13OCyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 6** Fit a gaussian mixture model to the dataset with 4 components (4 normal distributions). Then, just like you did in problem 4a, label each row of the data with the cluster defined by the gaussian mixture model and redo the scatter plot from problem 2b coloring the points by the GMM cluster label. Do you find similar clusters that you found with KMeans? Do you find similar clusters as the clusters we get when we group by pitch type?"
      ],
      "metadata": {
        "id": "WkCCVsAiO9sZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# problem 6\n"
      ],
      "metadata": {
        "id": "65RZabgFVB_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Problem 7**: One advantage that the gaussian mixture model has over KMeans is that you end up fitting a probability distribution to the data, which means that you can then sample new data points from that probability distribution. Simulate 1000 new pitches from Jacob DeGrom using your fitted gaussian mixture model and the sample function (see GaussianMixture documentation for help). Plot the pitches in a seaborn pairplot just like you did in the previous problem. Do the generated pitches look similar to the actual pitches used to train the model?\n",
        "\n",
        "<br>\n",
        "\n",
        "**Note**: You can probably imagine how useful it would be to a baseball team to simulate pitches from Jacob DeGrom. They can use that to simulate at bats between DeGrom and their own hitters. You are well on your way to becoming an expert baseball data scientist!"
      ],
      "metadata": {
        "id": "Y_VrCzijV4aG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# problem 7\n"
      ],
      "metadata": {
        "id": "akUSpExQVVSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 3** Choosing your clustering model\n",
        "\n",
        "Although the GMM model is nice because we can simulate pitches from it, that doesn't necessarily mean that it did the best job of learning the pitch type clusters.\n",
        "\n",
        "**Problem 8** Use the Silhouette score to compare the KMeans clustering with the GMM clustering. Then, decide which clustering algorithm you think is best considering all the work you have done so far in this lab, plus the silhouette score. Justify your choice."
      ],
      "metadata": {
        "id": "3xLdQQl_YCo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#problem 8\n"
      ],
      "metadata": {
        "id": "kE1ovbs-WmSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great work on this lab! To conclude I wanted to give you some data science job hunting advice. When I (Will Melville) was applying to baseball jobs, I started having a lot of success getting past the initial resume round when I added a \"relevant projects\" section to my resume. After completing this lab, if you were applying to a baseball job, or even a general data science job, you could add a bullet point to the relevant projects part of your resume that looked something like this:\n",
        "\n",
        "<br>\n",
        "\n",
        "**MLB Pitch Type Clustering (Spring 2025)**\n",
        "\n",
        "\n",
        "\n",
        "*   Used release speed, spin rate, and spin induced movement data to identify clusters of pitches corresponding to fastballs, changeups, curveballs, and sliders\n",
        "*   Implemented both a KMeans clustering model and a GMM clustering model\n",
        "*   Used silhouette scores and within cluster sum of squares to define the optimal number of clusters and to choose between KMeans and GMM\n",
        "* Used the final clustering model to simulate thousands of pitches from Jacob DeGrom\n",
        "\n",
        "<br>\n",
        "\n",
        "You would probably want to edit those bullet points and you may need to make it more concise depending on what else is on your resume, but hopefully you get the idea. A project like that on your resume would certainly intrigue me if you applied to the Rangers, and it may intrigue other data scientist recruiters! But be careful. If you do this you need to be prepared to talk about these bullet points in a job interview, so if chatgpt did this entire lab for you you're better off not adding that to your resume. You need to understand what you actually did in the lab!"
      ],
      "metadata": {
        "id": "DU6i1AnmcF2I"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vFJrQ-wmfpsm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
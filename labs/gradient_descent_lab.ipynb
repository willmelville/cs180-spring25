{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem 1**: Gradient Descent\n",
        "\n",
        "Let $f$ be the objective function that we want to minimize and $Df$ be its gradient. Throughout this lab, $f$ and $Df$ will be given to you, so you don't need to worry about calculating derivatives. $f$ will take as input a vector of length $n$, which we will represent in python using numpy arrays. $f$ will output a scalar and $Df$ will output another vector of length $n$, which is the gradient of $f$.\n",
        "\n",
        "For problem 1, you need to write a python function that takes as input the gradient function $Df$, an initial guess $x_0$, a learning rate (lr) defaulting to 0.1, a maximum number of gradient descent steps (maxiters) defaulting to 10,000, and a convergence tolerance level (tol), defaulting to 1e-5. Your function should perform k steps of gradient descent until either k > maxiters or until $||Df(x_k)||_{\\infty}$ < tol. Return a tuple containing the final value of x, a bool indicating whether or not the algorithm converged (True or False), and the number of iterations computed.\n",
        "\n",
        "For those who are unfamiliar with the notation, $||Df(x_k)||_{\\infty}$ is the infinity norm of the gradient of $f$ at x after k iterations, and the infinity norm of a vector is the max of the absolute value of the vector. To check if the infinity norm is less than the convergence tolerance in python, you would type\n",
        "\n",
        "\n",
        "```\n",
        "np.max(np.abs(Df(xk))) < tol\n",
        "```\n",
        "or you could type\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "np.linalg.norm(Df(xk), ord = np.inf) < tol\n",
        "```"
      ],
      "metadata": {
        "id": "8mht_jNJ-fkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "LRyQblMCI0qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SDzi4OZ-QaE"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(Df, x0, lr = 0.1, maxiters = 10000, tol = 1e-5):\n",
        "  # Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, to test your function, run the following cell. In this cell I provide the gradient for the function $f(x, y, z) = x^4 + y^4 + z^4$. The initial value I give you is [x, y, z] = [1, 2, -1]. The minimizing input to this function is $x = y = z = 0$, but when I ran it with my solution I ended up with an approximate minimizer of [0.0136, -0.0136, -0.0136], which I converged to in a little under 7000 iterations. You should get similar results.\n",
        "\n",
        "If you do get similar results, feel free to play around with your gradient_descent function and try to minimize different functions! You could also see what happens when you change the learning rate or the starting point, although we will experiment more with that in problems 2 and 3."
      ],
      "metadata": {
        "id": "RWlwS83uIHcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Df = lambda x: 4 * x **3\n",
        "x0 = np.array([1,2,-1])\n",
        "\n",
        "gradient_descent(Df, x0)"
      ],
      "metadata": {
        "id": "FB1smWTuIFws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem 2**: Experimenting with Learning Rates\n",
        "\n",
        "The choice of learning rate in gradient descent is very important. If your learning rate is too small, it may take you forever to reach the optimizing point. If your learning rate is too large, you may jump past the optimizing point over and over again, never actually stopping on it. In this problem, we are going to try to visualize how different learning rates affect the path that gradient descent takes on the function surface. The function we are going to be optimizing is $f(x, y) = 3(1-x)^2e^{-x^2-(y+1)^2} - 10(\\frac{x}{5} - x^3 - y^5)e^{-x^2-y^2} - \\frac{1}{3}e^{-(x+1)^2-y^2}$.\n",
        "\n",
        "Since we want to visualize the path that we take with gradient descent, you need a gradient descent function that returns every x vector that you visited. Define a new function that does the same thing as your function in problem 1, only instead of returning a tuple with the final x value, a bool for convergence, and the number of iterations, return a numpy array with n rows and len(x) columns where n is the number of gradient descent steps you took, so the $k^{th}$ row of your output is the value of $x$ you got on gradient descent step $k$. This function should be fairly easy to define since it's almost identical to your function from problem 1. You just need to store x after each step and then return all the x's once you converge or hit maxiters iterations."
      ],
      "metadata": {
        "id": "DhY9z5BtW8FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent_2(Df, x0, lr = 0.1, maxiters = 10000, tol = 1e-5):\n",
        "  #your code here"
      ],
      "metadata": {
        "id": "AzuTjk2nM1bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code cell, I define $f$ and $Df$. I also define two functions. The first one takes as input a gradient descent path (the numpy array output of your function for problem 2) and plots $f$ along with the gradient descent path in three dimensions. The second one also takes as input a gradient descent path and creates a contour plot for $f$ and shows the gradient descent path in 2 dimensions. The 3-d plot may be a little hard to interpret because some of the peaks and valleys are obscured by other peaks and valleys, but the combination of the 2-d plot and the 3-d plot should help us to see how the learning rate affects the convergence of gradient descent!\n",
        "\n",
        "<br>\n",
        "\n",
        "You need to run 4 experiments. In each experiment, choose the starting point as `x0 = np.array([1.2, -0.2])`. The experiments are:\n",
        "\n",
        "1. Run your gradient_descent_2 function with x0 = np.array([1.2, -0.2]) and lr = 0.00001. Use the default values for maxiters and tol. Plot both the 3-d plot and the contour plot.\n",
        "\n",
        "2. Repeat experiment 1, but this time choose lr = 0.01.\n",
        "\n",
        "3. Repeat experiment 2, but this time choose lr = 0.045.\n",
        "\n",
        "4. Repeat experiment 3, but this time choose lr = 0.15. Also, set maxiters to 10.\n",
        "\n",
        "Once you complete those experiments, answer these questions in a text cell:\n",
        "1. Which of the four learning rates that you tested do you think is the best option?\n",
        "\n",
        "2. What's the downside of a learning rate that's too small?\n",
        "\n",
        "3. What's the downside of a learning rate that's too large?"
      ],
      "metadata": {
        "id": "WuqhLG6GE3Qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#f and Df\n",
        "f = lambda x: 3 * (1 - x[0])**2 * np.exp(-x[0]**2 - (x[1]+1)**2) - 10 * (x[0] / 5 - x[0]**3 - x[1]**5) * np.exp(-x[0]**2 - x[1]**2) - 1/3 * np.exp(-(x[0]+1)**2 - x[1]**2)\n",
        "df1 = lambda x: -(6*x[0]**3 - 12*x[0]**2 + 6)*np.exp(-x[0]**2 - (x[1]+1)**2) - (20*x[0]**4 - 34*x[0]**2 + 20 * x[1]**5 * x[0] + 2)*np.exp(-x[0]**2 - x[1]**2) + 2/3 * (x[0]+1)*np.exp(-(x[0]+1)**2 - x[1]**2)\n",
        "df2 = lambda x: -6*(x[0]-1)**2 * (x[1]+1) * np.exp(-x[0]**2 - (x[1]+1)**2) - (20*x[1]**6 - 50*x[1]**4 + (20*x[0]**3 - 4*x[0])*x[1])*np.exp(-x[0]**2 - x[1]**2) + 2/3 * x[1] *np.exp(-x[1]**2 - (x[0]+1)**2)\n",
        "Df = lambda x: np.array([df1(x), df2(x)])\n",
        "\n",
        "#f(X, Y)\n",
        "X, Y = np.meshgrid(np.linspace(-2,2,100), np.linspace(-2,2,100))\n",
        "Z = np.ones_like(Y)\n",
        "for i in range(X.shape[0]):\n",
        "  for j in range(X.shape[1]):\n",
        "    Z[i,j] = f(np.array([X[i,j], Y[i,j]]))\n",
        "\n",
        "\n",
        "#function for 3-d plot\n",
        "def plot_3d_path(grad_path):\n",
        "  ax = plt.subplot(1,1,1, projection = '3d')\n",
        "  ax.plot_surface(X, Y, Z, alpha = 0.7)\n",
        "\n",
        "  ax.plot(grad_path[:,0], grad_path[:,1], [f(x) for x in grad_path], 'r.-')\n",
        "  plt.show()\n",
        "\n",
        "#function for 2-d contour plot\n",
        "def plot_2d_path(grad_path):\n",
        "  plt.contourf(X, Y, Z)\n",
        "  plt.colorbar()\n",
        "  plt.plot(grad_path[:,0], grad_path[:,1], 'r.-')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "vCVnHqULdF4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I gave you the code for experiment one as an example for the other experiements"
      ],
      "metadata": {
        "id": "R-nhdBzQdbq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# part 1 3-d plot\n",
        "xvals = gradient_descent_2(Df, np.array([1.2, -0.2]), lr = 0.00001)\n",
        "plot_3d_path(xvals)"
      ],
      "metadata": {
        "id": "2BAPQAblgLji"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 1 contour plot\n",
        "plot_2d_path(xvals)"
      ],
      "metadata": {
        "id": "LruIIn67hb0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# part 2 3-d plot\n"
      ],
      "metadata": {
        "id": "uZ7PWvo0h66N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 2 contour plot\n"
      ],
      "metadata": {
        "id": "dSWje3SgJSEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 3 3-d plot\n"
      ],
      "metadata": {
        "id": "k2PZCjMaJV3N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 3 contour plot\n"
      ],
      "metadata": {
        "id": "RPkcs3-QJoX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# part 4 3-d plot\n"
      ],
      "metadata": {
        "id": "nvP9AmMIJseZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# part 4 contour plot\n"
      ],
      "metadata": {
        "id": "B7J0nyldKA3Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Written responses**: answer the written questions in this text cell.\n",
        "\n",
        "1.\n",
        "\n",
        "2.\n",
        "\n",
        "3."
      ],
      "metadata": {
        "id": "RmDWu6yUKvIt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem 3**: Experimenting with different starting points\n",
        "\n",
        "As you may recall from back when you took calculus, the derivative (gradient) of a function is 0 not only at the global minimum, but also at local minima. That means that unfortunately, the choice of starting point in gradient descent may affect whether you converge to the global minimum (which is ideal) or if you converge to a local minimum. In this problem, you are going to visualize the effect that starting point has on convergence to global/local minima. You will use the same function you defined for the previous problem, gradient_descent_2, and you will again use the provided plot_3d_path and plot_2d_path functions. You will run four experiments:\n",
        "\n",
        "1. Run your gradient_descent_2 function with x0 = np.array([1.2, -0.2]) and lr = 0.045. Use the default values for maxiters and tol. Plot both the 3-d plot and the contour plot. (Note this is the same experiment as experiment 3 in problem 2, but that's intentional because you will want to compare the results of this experiment directly with the results of the next experiment).\n",
        "\n",
        "2. Repeat experiment 1, but this time choose x0 = np.array([1.2, -0.1])\n",
        "\n",
        "3. Repeat experiment 2, but this time choose x0 = np.array([0, 1.55])\n",
        "\n",
        "4. Repeat experiment 3, but this time choose x0 = np.array([-0.05, 1.55])\n",
        "\n",
        "After running the experiments, briefly write about what you are seeing. How much of an effect can the starting point have on where gradient descent ends up? Do we need a significant change in starting point to end up with a significant change in ending point?"
      ],
      "metadata": {
        "id": "_wAbZBlMLpTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#part 1 3-d plot\n"
      ],
      "metadata": {
        "id": "Av__dnpkKFLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 1 contour plot\n"
      ],
      "metadata": {
        "id": "_45DADg-M8hm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 2 3-d plot\n"
      ],
      "metadata": {
        "id": "kKUuhpmFM_Ar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 2 contour plot\n"
      ],
      "metadata": {
        "id": "o6m4hc4RNEdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 3 3-d plot\n"
      ],
      "metadata": {
        "id": "nDW-5sXYNHIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 3, contour plot\n"
      ],
      "metadata": {
        "id": "GAPOE09ENoo0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 4 3-d plot\n"
      ],
      "metadata": {
        "id": "T-jH4iZoNr_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#part 4, contour plot\n"
      ],
      "metadata": {
        "id": "19R62_ACN4R7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write your thoughts here**:\n"
      ],
      "metadata": {
        "id": "vBUItzx1OUbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus**: Great work on problems 2 and 3! I got the function for these problems from a cool web app that shows how different starting points and learning rates effects gradient descent convergence. Feel free to go play around with that web app, and you'll notice that your python code gets similar results based on the different starting points and learning rates! Feel free to test out other starting points and learning rates to compare with the web app if you so desire!\n",
        "\n",
        "https://blog.skz.dev/gradient-descent"
      ],
      "metadata": {
        "id": "0d0ecLfzOwqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Problem 4:** Logistic Regression\n",
        "\n",
        "Logistic regression is a type of supervised machine learning algorithm. It is a binary classifier, meaning it takes data as input to predict a target variable of 1's and 0's. Specifically, logistic regression defines the probability that the target variable $y_i = 1$ given the input data vector $x_i$ as\n",
        "\n",
        "$P(y_i = 1 | x_i) = p_i = \\frac{1}{1 + exp(-(\\beta^Tx_i))}$.\n",
        "\n",
        "Here, $\\beta = [\\beta_1, \\ldots, \\beta_n]$ is a vector with the same number of entries as there are input variables in the vector $x_i$. $\\beta$ are the parameters that we want to learn. To do so, we need to define an objective function that we want to optimize. The probability of observing the outcome variables $y_i$ is given by the liklihood function\n",
        "\n",
        "$\\mathcal{L}(\\beta) = \\prod_{i=1}^m p_i^{y_i}(1-p_i^{1-y_i})$,\n",
        "\n",
        "where $m$ is the number of rows of data. The goal of logistic regression is to find the $\\beta$ parameters that maximize this likelihood. It turns out that maximizing this likelihood is equivalent to minimizing the negative log liklihood, which is $-\\text{log} \\mathcal{L}(\\beta)$, so the goal is to find the $\\beta$ that minimizes the negative log liklihood. Fortunately for us, we have just coded up an algorithm, gradient descent, that we can use to minimize functions! For this problem you will use your gradient descent implementation to learn a logistic regression model.\n",
        "\n",
        "If this section seems overwhelming, don't worry, we will cover logistic regression in more detail when we cover supervised learning in class. I wanted to include it in this lab though because in python's scikit learn package, the default optimization method for learning logistic regression models is an algorithm called lbfgs. Obviously lbfgs is not gradient descent, but it shares some similarities with gradient descent, namely that it is an iterative optimizer that works by taking steps in the direction of the negative gradient! Thus, I want you to see through this exercise one of the many useful applications of gradient based iterative optimization methods!  \n",
        "\n",
        "In the following cell, I load the data for you. The data is the breast cancer dataset which is available from scikit learn. We are only using the first 100 rows and the first 10 columns of that dataset. The goal is to predict the target variable, which is 1 if the diagnosis is malignant and 0 if it is benign. I also define the objective function $f$ in the following cell, which is the negative log likelihood, and the gradient $Df$. Finally, I define the starting x0.\n",
        "\n",
        "You are going to test out different learning rates. For learning rates equal to 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, and 0.12 I want you to run gradient descent using your gradient_descent function from problem 1 with the x0 and Df defined in the following cell. Set tol to 1e-2 for this problem. After running gradient descent for each learning rate, store the number of iterations it took for gradient descent to converge at that learning rate (or store the max number of iterations if it didn't converge). Also, take the final value of x and run it through the f function defined in the following cell and store that value. That is the negative log likelihood of the logistic regression model learned with that learning rate. Once you have done that for each learning rate, create a scatter plot with learning rates on the x-axis and number of iterations on the y axis. Then create another scatter plot with learning rate on the x axis and negative log likelihood on the y axis. Finally, answer which learning rate gives the best results based on your plots."
      ],
      "metadata": {
        "id": "gdh3PddPZnop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the breast cancer dataset\n",
        "data = sklearn.datasets.load_breast_cancer()\n",
        "X = data['data'][:100, :10]\n",
        "y = data['target'][:100]\n",
        "\n",
        "#z score X\n",
        "X = StandardScaler().fit_transform(X)\n",
        "\n",
        "#define the our objective function f, which is the negative log likelihood function, and its gradient\n",
        "f = lambda beta: np.sum(np.log(1 + np.exp(-X @ beta)) + (1-y) * (X @ beta))\n",
        "Df = lambda beta: X.T @ (1/(1 + np.exp(-X@beta)) - y)\n",
        "\n",
        "#define the initial value of x\n",
        "x0 = np.ones(10)\n",
        "\n",
        "#learning rates\n",
        "learning_rates = [0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12]"
      ],
      "metadata": {
        "id": "bDHN49RCN6tF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# your code to test all the different learning rates and calculate the number of iterations and the negative log liklihood\n"
      ],
      "metadata": {
        "id": "BMEq1Vp3ewlc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot of learning rates and iterations\n"
      ],
      "metadata": {
        "id": "s_SHJ5pJnukV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot of learning rates and negative log likelihood\n"
      ],
      "metadata": {
        "id": "zChZ-DfsvrWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Which learning rate gave the best results?**\n",
        "\n",
        "**Your answer here:**"
      ],
      "metadata": {
        "id": "PJgAf8TS4RAT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finally**: With whichever learning rate you thought gave the best result, learn the optimal beta parameters using gradient descent with that learning rate. Run your trained model on the data and evaluate the accuracy using the following code\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "probs = 1 / (1+np.exp(-X @ beta))\n",
        "is_malignant = probs > 0.5\n",
        "accuracy = np.mean(is_malignant == y)\n",
        "```\n",
        "\n",
        "where beta is the output of your gradient descent optimizer. Print the accuracy!\n"
      ],
      "metadata": {
        "id": "ti4K5L5g4fR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#your code here\n"
      ],
      "metadata": {
        "id": "ScCO-_rIvxii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kXdFGag35axk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
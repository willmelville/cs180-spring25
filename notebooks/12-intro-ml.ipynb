{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rhodes-byu/cs180-winter25/blob/main/notebooks/12-intro-ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.datasets as datasets\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.stats import randint\n",
    "\n",
    "sns.set(style = \"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### **Loading a Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = datasets.load_wine() # Pick a dataset: iris, wine, breast_cancer\n",
    "print(data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.feature_names)\n",
    "print(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data  # Features\n",
    "y = data.target  # Labels\n",
    "\n",
    "df = pd.DataFrame(X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "\n",
    "# Check if the target variable is balanced\n",
    "target_counts = df['target'].value_counts()\n",
    "print(target_counts)\n",
    "\n",
    "# Plot the distribution of the target variable\n",
    "sns.countplot(x = 'target', data = df)\n",
    "plt.title('Distribution of Target Variable')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting Data into Training and Testing Sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Testing data shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training and Evaluating a K-Nearest Neighbors (KNN) Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "\n",
    "# Train the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"KNN Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training and Evaluating a Logistic Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "log_reg = LogisticRegression(max_iter = 200)\n",
    "\n",
    "# Train the model\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log_reg = log_reg.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training and Evaluating a Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_tree = tree.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_tree))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Visualizing the Decision Tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree, filled = True, feature_names = data.feature_names, class_names = data.target_names);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation for each model\n",
    "models = {'KNN': knn, 'Decision Tree': tree, 'Logistic Regression': log_reg}\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring = 'f1_weighted')\n",
    "    print(f\"{name} Cross-Validation Score: {scores.mean():.2f} Â± {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing the Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_knn)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=data.target_names, yticklabels=data.target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for KNN\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Scaling: StandardScaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (zero mean, unit variance)\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on training data and transform both train and test sets\n",
    "scaler.fit(X_train)\n",
    "\n",
    "# Alternatively:\n",
    "# X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"Mean of scaled features (train):\", X_train_scaled.mean(axis=0))\n",
    "print(\"Standard deviation of scaled features (train):\", X_train_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Scaling: MinMaxScaler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale features to the [0, 1] range\n",
    "minmax_scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler on training data and transform both train and test sets\n",
    "X_train_minmax = minmax_scaler.fit_transform(X_train)\n",
    "X_test_minmax = minmax_scaler.transform(X_test)\n",
    "\n",
    "print(\"Minimum of scaled features (train):\", X_train_minmax.min(axis=0))\n",
    "print(\"Maximum of scaled features (train):\", X_train_minmax.max(axis=0))\n",
    "\n",
    "print(\"Minimum of scaled features (test):\", X_test_minmax.min(axis=0))\n",
    "print(\"Maximum of scaled features (test):\", X_test_minmax.max(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training a K-Nearest Neighbors (KNN) Classifier with Scaled Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the model on scaled data\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn_scaled = knn.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"KNN Accuracy (scaled):\", accuracy_score(y_test, y_pred_knn_scaled))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_knn_scaled))\n",
    "\n",
    "print(\"KNN Accuracy (not scaled):\", accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training a Decision Tree Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_tree_scaled = tree.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Decision Tree Accuracy (scaled):\", accuracy_score(y_test, y_pred_tree_scaled))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_tree_scaled))\n",
    "\n",
    "print(\"Decision Tree Accuracy:\", accuracy_score(y_test, y_pred_tree))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training a Logistic Regression Model with Scaled Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "log_reg = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Train the model on scaled data\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_log_reg_scaled = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Logistic Regression Accuracy (scaled):\", accuracy_score(y_test, y_pred_log_reg_scaled))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_log_reg_scaled))\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_log_reg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cross-Validation, Scaled Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform 5-fold cross-validation for each model\n",
    "models = {\n",
    "    'KNN (scaled)': KNeighborsClassifier(n_neighbors=3),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'Logistic Regression (scaled)': LogisticRegression(max_iter=200)\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    # Apply scaling where necessary\n",
    "    if 'scaled' in name:\n",
    "        X_transformed = scaler.fit_transform(X)\n",
    "    else:\n",
    "        X_transformed = X\n",
    "    \n",
    "    scores = cross_val_score(model, X_transformed, y, cv=5)\n",
    "    print(f\"{name} Cross-Validation Accuracy: {scores.mean():.2f} Â± {scores.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing the Confusion Matrix (Scaled Data)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute confusion matrix for one model (e.g., Logistic Regression with scaled data)\n",
    "cm = confusion_matrix(y_test, y_pred_log_reg_scaled)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=data.target_names, yticklabels=data.target_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix for Logistic Regression (Scaled)\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperparameter Tuning**: GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Hyperparameter tuning for KNN\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [1, 3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'cosine']\n",
    "}\n",
    "\n",
    "grid_knn = GridSearchCV(KNeighborsClassifier(), param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters for KNN:\", grid_knn.best_params_)\n",
    "print(\"Best cross-validation score for KNN:\", grid_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the test set\n",
    "best_knn = grid_knn.best_estimator_\n",
    "y_pred_knn_tuned = best_knn.predict(X_test_scaled)\n",
    "print(\"Test accuracy for best KNN model:\", accuracy_score(y_test, y_pred_knn_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(grid_knn.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Mean Test Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Mean Test Scores for KNN')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing Hyperparameter Search Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GridSearchCV results for KNN\n",
    "results_knn = pd.DataFrame(grid_knn.cv_results_)\n",
    "results_knn_pivot = results_knn.pivot_table(index='param_n_neighbors',\n",
    "                                            columns='param_weights', \n",
    "                                            values='mean_test_score')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(\n",
    "    results_knn_pivot,\n",
    "    annot=True, fmt=\".3f\", cmap=\"viridis\"\n",
    ")\n",
    "plt.title(\"KNN Hyperparameter Search Results\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.xlabel(\"Number of Neighbors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Using RandomizedSearchCV** for Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Hyperparameter tuning for Decision Tree\n",
    "param_dist_tree = {\n",
    "    'max_depth': [None, 5, 10, 20, 30, 40],\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "random_tree = RandomizedSearchCV(DecisionTreeClassifier(random_state=42), param_dist_tree,\n",
    "                                 n_iter=20, cv=5, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "                                 \n",
    "random_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters for Decision Tree:\", random_tree.best_params_)\n",
    "print(\"Best cross-validation score for Decision Tree:\", random_tree.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the test set\n",
    "best_tree = random_tree.best_estimator_\n",
    "y_pred_tree_tuned = best_tree.predict(X_test)\n",
    "print(\"Test accuracy for best Decision Tree model:\", accuracy_score(y_test, y_pred_tree_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(random_tree.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Mean Test Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Mean Test Scores for DT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Hyperparameter Tuning for Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Hyperparameter tuning for Logistic Regression\n",
    "param_grid_log_reg = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength (lambda values from notes)\n",
    "    'penalty': ['none', 'l2'],  # Regularization technique\n",
    "    'max_iter': [10, 100, 200, 500]  # Iterations\n",
    "}\n",
    "\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(random_state=42), param_grid_log_reg, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_log_reg.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best parameters for Logistic Regression:\", grid_log_reg.best_params_)\n",
    "print(\"Best cross-validation score for Logistic Regression:\", grid_log_reg.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on the test set\n",
    "best_log_reg = grid_log_reg.best_estimator_\n",
    "y_pred_log_reg_tuned = best_log_reg.predict(X_test_scaled)\n",
    "print(\"Test accuracy for best Logistic Regression model:\", accuracy_score(y_test, y_pred_log_reg_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(grid_log_reg.cv_results_['mean_test_score'])\n",
    "plt.xlabel('Mean Test Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Mean Test Scores for Log. Reg.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparing the Tuned Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare accuracy for tuned models\n",
    "models = {\n",
    "    \"KNN (tuned)\": best_knn,\n",
    "    \"Decision Tree (tuned)\": best_tree,\n",
    "    \"Logistic Regression (tuned)\": best_log_reg\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test_scaled if \"Logistic\" in name or \"KNN\" in name else X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(f\"{name} Test Accuracy: {accuracy:.2f}, F1 Score: {f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

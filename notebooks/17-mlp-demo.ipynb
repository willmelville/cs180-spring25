{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f45630d",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rhodes-byu/cs180-winter25/blob/main/notebooks/17-mlp-demo\n",
    ".ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a4787b",
   "metadata": {},
   "source": [
    "# MLPClassifier with Scikit-Learn\n",
    "\n",
    "This notebook demonstrates how to use the `MLPClassifier` from `scikit-learn` for classification and regression.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2affc54",
   "metadata": {},
   "source": [
    "## Introduction to Neural Networks\n",
    "\n",
    "A **neural network** consists of layers of interconnected nodes (neurons), inspired by the human brain. The simplest neural network, a **multilayer perceptron (MLP)**, includes:\n",
    "- **Input layer**: receives features.\n",
    "- **Hidden layers**: perform nonlinear transformations using activation functions.\n",
    "- **Output layer**: produces the final prediction.\n",
    "\n",
    "Each connection has an associated **weight**, and each neuron typically has a **bias** term. During training, the model adjusts weights to minimize prediction error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfdb9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_moons, fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfaf935",
   "metadata": {},
   "source": [
    "## Moons Dataset Revisited\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd42872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic dataset (moons)\n",
    "X, y = make_moons(n_samples = 1000, noise = 0.2, random_state = 42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Further split into validation data\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14390552",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"X_test shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8798dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', s=10)\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"Scatter Plot of Moons Dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97fd551",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10), max_iter = 1000, random_state = 42)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456960ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.predict(X_val)\n",
    "y_pred_val = mlp.predict(X_val)\n",
    "print(\"Validation set classification report:\")\n",
    "print(classification_report(y_val, y_pred_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17402eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConfusionMatrixDisplay.from_predictions(y_val, y_pred_val)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421d802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: decision boundary\n",
    "def plot_decision_boundary(model, X, y, ax):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3)\n",
    "    scatter = ax.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k')\n",
    "    legend1 = ax.legend(*scatter.legend_elements(), title=\"Classes\")\n",
    "    ax.add_artist(legend1)\n",
    "    ax.set_title(\"MLPClassifier Decision Boundary\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90199ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_decision_boundary(mlp, X_test, y_test, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b6925",
   "metadata": {},
   "source": [
    "## Visualizing the Loss Curve\n",
    "\n",
    "You can monitor training progress by inspecting the loss curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e96786",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mlp.loss_curve_)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss Curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bbfd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_partial = MLPClassifier(hidden_layer_sizes=(10,), max_iter=1, warm_start=True, random_state=42,\n",
    "                            activation = 'tanh')\n",
    "\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "train_accuracy = []\n",
    "val_accuracy = []\n",
    "\n",
    "for _ in range(10000):  # Number of epochs\n",
    "    mlp_partial.partial_fit(X_train, y_train, classes=np.unique(y_train))\n",
    "    train_loss.append(mlp_partial.loss_)\n",
    "    val_loss.append(-np.mean(y_val * np.log(mlp_partial.predict_proba(X_val)[:, 1]) + \n",
    "                              (1 - y_val) * np.log(1 - mlp_partial.predict_proba(X_val)[:, 1])))\n",
    "    train_accuracy.append(mlp_partial.score(X_train, y_train))\n",
    "    val_accuracy.append(mlp_partial.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bfa4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Plot the loss curves\n",
    "ax[0].plot(train_loss, label=\"Training Loss\")\n",
    "ax[0].plot(val_loss, label=\"Validation Loss\")\n",
    "ax[0].set_xlabel(\"Epochs\")\n",
    "ax[0].set_ylabel(\"Loss\")\n",
    "ax[0].set_title(\"Training and Validation Loss Curve\")\n",
    "ax[0].legend()\n",
    "\n",
    "# Plot the accuracy curves\n",
    "ax[1].plot(train_accuracy, label=\"Training Accuracy\")\n",
    "ax[1].plot(val_accuracy, label=\"Validation Accuracy\")\n",
    "ax[1].set_xlabel(\"Epochs\")\n",
    "ax[1].set_ylabel(\"Accuracy\")\n",
    "ax[1].set_title(\"Training and Validation Accuracy Curve\")\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f39e44",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "Activation functions introduce non-linearity into the network. Common ones include:\n",
    "- **ReLU (Rectified Linear Unit)**: `f(x) = max(0, x)`\n",
    "- **Sigmoid**: `f(x) = 1 / (1 + exp(-x))`\n",
    "- **Tanh**: `f(x) = tanh(x)`\n",
    "\n",
    "Different activations affect learning dynamics. Historically, **Sigmoid** was important due to its connection with Logistic Regression. In practice, **ReLU** is most frequently used today due to faster training times and help with the vanishing gradient problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = ['identity', 'logistic', 'tanh', 'relu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1204e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "scores = {}\n",
    "for activation in activations:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000, activation=activation, random_state=42)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    models[activation] = mlp\n",
    "    scores[activation] = mlp.score(X_val, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd34359c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 4, figsize=(30, 8))\n",
    "\n",
    "for i, (activation, model) in enumerate(models.items()):\n",
    "    score = scores[activation]\n",
    "    plot_decision_boundary(model, X_test, y_test, ax[i])\n",
    "    ax[i].set_title(f\"Activation: {activation}, Score: {np.round(score, 3)}\")  # Set title after plotting\n",
    "    ax[i].set_xlabel(\"Feature 1\")\n",
    "    ax[i].set_ylabel(\"Feature 2\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0e42bc",
   "metadata": {},
   "source": [
    "## Hidden Layer Sizes\n",
    "\n",
    "The `hidden_layer_sizes` parameter controls the number and size of hidden layers, e.g.:\n",
    "- `(10,)`: one hidden layer with 10 neurons\n",
    "- `(100,)`: one large hidden layer\n",
    "- `(50, 30)`: two hidden layers with 50 and 30 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07e6983",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_sizes = [(1,), (2,), (10,), (50,), (100,), (10, 10), (50, 10), (100, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744886dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sizes in hidden_sizes:\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=sizes, max_iter=1000, activation='relu', random_state=42)\n",
    "    mlp.fit(X_train, y_train)\n",
    "    y_pred_val = mlp.predict(X_val)\n",
    "    print(f\"Hidden sizes: {sizes}\")\n",
    "    print(\"Validation set classification report:\")\n",
    "    print('Accuracy:', mlp.score(X_val, y_val), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7abfd6b",
   "metadata": {},
   "source": [
    "## Overfitting and Regularization\n",
    "\n",
    "Train a model with large hidden layers to observe overfitting (high train accuracy, low test accuracy).\n",
    "\n",
    "Then mitigate using L2 regularization:\n",
    "\n",
    "```python\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), alpha=0.01)\n",
    "```\n",
    "\n",
    "You can also conceptually introduce **dropout** and **early stopping** as regularization strategies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8518c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(10), max_iter=1000, activation='relu', random_state=42, alpha = 10)\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "y_pred_val = mlp.predict(X_val)\n",
    "print(\"Validation set classification report:\")\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9425fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_decision_boundary(mlp, X_test, y_test, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa0b4ce",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9768fbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'hidden_layer_sizes': [(10,), (50,), (100,), (150,)], # Number of neurons in each hidden layer\n",
    "    'activation': ['tanh'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.0001, 0.05], # Regularization parameter\n",
    "    'learning_rate': ['constant', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1], # Initial learning rate\n",
    "    'max_iter': [1000],\n",
    "}\n",
    "\n",
    "cv = RandomizedSearchCV(mlp, params, n_iter=15, cv=5, verbose=2, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc94349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = RandomizedSearchCV(mlp, param_distributions = params, n_iter=10, cv=3, random_state=42)\n",
    "cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258bd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51188842",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627150e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "plot_decision_boundary(cv.best_estimator_, X_test, y_test, ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe608303",
   "metadata": {},
   "source": [
    "## MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5bff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_openml('mnist_784', version = 1, parser = 'auto')\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3cd23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max val: ', X.values.max())\n",
    "print('Min val: ', X.values.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57130976",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X / 255.0  # Normalize pixel values to [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282422f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "\n",
    "X_test = X[60000:]\n",
    "y_test = y[60000:]\n",
    "\n",
    "# Split of validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e377037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10, random_state=42)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa60fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.predict(X_val)\n",
    "y_pred_val = mlp.predict(X_val)\n",
    "\n",
    "print(\"Validation set classification report:\")\n",
    "print(classification_report(y_val, y_pred_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a8ca48",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = ConfusionMatrixDisplay.from_estimator(mlp, X_val, y_val, cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53df9545",
   "metadata": {},
   "source": [
    "## Visualizing `Difficult` examples\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bd5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities for the validation set\n",
    "y_proba_val = mlp.predict_proba(X_val)\n",
    "\n",
    "# Identify misclassified points\n",
    "misclassified_indices = np.where(y_val != y_pred_val)[0]\n",
    "\n",
    "# Calculate discrepancies for misclassified points\n",
    "discrepancies = np.abs(y_proba_val[misclassified_indices, y_val.iloc[misclassified_indices].astype(int)] - \n",
    "                       y_proba_val[misclassified_indices, y_pred_val[misclassified_indices].astype(int)])\n",
    "\n",
    "# Get indices of misclassified points with the highest discrepancies\n",
    "top_discrepancy_indices = misclassified_indices[np.argsort(-discrepancies)[:5]]\n",
    "\n",
    "# Display predicted probabilities and true y values for these points\n",
    "print(\"Predicted probabilities for misclassified points with highest discrepancies:\")\n",
    "print(y_proba_val[top_discrepancy_indices].round(3))\n",
    "print(\"\\nTrue y values for these points:\")\n",
    "print(y_val.iloc[top_discrepancy_indices].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3af73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(top_discrepancy_indices), figsize=(15, 5))\n",
    "\n",
    "for i, idx in enumerate(top_discrepancy_indices):\n",
    "    ax = axes[i]\n",
    "    image = X_val.iloc[idx].values.reshape(28, 28)  # Reshape the flattened image to 28x28\n",
    "    ax.imshow(image, cmap='gray')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f\"True: {y_val.iloc[idx]}, Pred: {y_pred_val[idx]}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73fb7442",
   "metadata": {},
   "source": [
    "## Your Turn!\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30e1d33",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "The **Fashion MNIST** dataset is a collection of 70,000 grayscale images of size 28x28 pixels, representing 10 categories of clothing items, such as T-shirts, trousers, and shoes. It is designed as a drop-in replacement for the MNIST dataset, providing a more challenging benchmark for machine learning models. Each image is labeled with one of the 10 classes, and the dataset is split into 60,000 training samples and 10,000 test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29af33e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch Fashion MNIST\n",
    "fashion_mnist = fetch_openml('Fashion-MNIST', version=1, as_frame=False, parser = 'auto')\n",
    "\n",
    "# Extract features and labels\n",
    "X, y = fashion_mnist[\"data\"], fashion_mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9485f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_names = {0: \"T-shirt/top\", 1: \"Trouser\", 2: \"Pullover\", 3: \"Dress\", 4: \"Coat\",\n",
    "               5: \"Sandal\", 6: \"Shirt\", 7: \"Sneaker\", 8: \"Bag\", 9: \"Ankle boot\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac1af83",
   "metadata": {},
   "source": [
    "### 0. Visualize the data\n",
    "Display the first 10 data points. Include the label names in the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d3ef74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05fb9838",
   "metadata": {},
   "source": [
    "### 1. Data Prep.\n",
    "Normalize the dataset and split in to 70/30 train-test set sizes. Further split the test set into test and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597964b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b9be69d8",
   "metadata": {},
   "source": [
    "### 2. Train a Model\n",
    "Train an MLP. What accuracy are you getting on the validation set? Try a few more parameter combinations and select the best combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef11b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "184f81bd",
   "metadata": {},
   "source": [
    "### 3. Model Validation\n",
    "Now using the test set, evaluate the model performance. \n",
    "Create a confusion matrix; where are most of the misclasifications occuring?  \n",
    "Do the misclassifications seem to make sense based on the target labels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93621b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b5451d5",
   "metadata": {},
   "source": [
    "### 4. Visualizing Miscalssified Points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf64b9e",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "Visualize some of the misclassified points. Include in the plot title the true and predicted labels. Can you see why the model might have been confused?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30524d04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ac7cdce",
   "metadata": {},
   "source": [
    "### 5. Compare with other models\n",
    "Try another model we have covered in class.  Do any of the models outperform the MLP on the test set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d72a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rfgap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
